---
layout: post
title:  "Their IP mountain was drilled away by AI 'mining' companies for profit. Are they owed anything?"
author: shirish
categories: [ engineering, software, ai, llm, ethics, generative-ai, machine-learning ]
image: "assets/images/bard.jpg"
---

Data ownership for large language models is a thorny, complex and contentious issue. AI companies have unlocked huge productivity potential by training their massive models. This was at the cost of freely appropriating data from original writers, artists, musicians and creators in general. Most of them were never paid or consented to their output being used to train the models. How do we square the data ownership circle?

**Introduction**

The rise of generative AI, triggered by openAI's chatGPT has ignited a revolution in creative expression. These massive models can produce eerily realistic text, images, and even music, blurring the lines between human and machine-made art. It raises a new question: who owns the data used to train these models, and consequently, who has the rights for the profits the models generate?

This essay discusses the complex issue of data ownership in the context of generative models. We will explore the ethical considerations, legal challenges, and societal implications arising from this technological shift. We will try to illuminate the potential pitfalls and see if we can build a future where innovation and creativity might coexist peacefully.

At the heart of the issue lies the question of ownership. Traditionally, copyright and intellectual property laws have protected the creative works of individuals. However, generative models operate differently. They don't simply copy existing content; they appear to learn from vast datasets of text, images, and code, extracting patterns and generating entirely new outputs. This raises the trillion-dollar question: does the ownership of the training data automatically translate to ownership of the generated content?

The answer is far from clear-cut. Some argue that the model simply acts as a tool, and the true creators are the individuals who provided the data. They believe that the output reflects the collective creativity embedded in the training data. Therefore, they argue, ownership should be shared. This perspective aligns with the "fair use" doctrine, which allows for limited use of copyrighted material for transformative purposes.

Others argue that the model itself (or the user of the model) is the true creator. They argue that the models transform training data into something entirely new, guided by the end user. They believe that the developer of the model (or the user) should hold ownership rights. They compare it to how a painter owns the final artwork even though they use pigments and brushes created by others.

The contention is this: are LLM's similar to search engines and information-retrieval systems, or are they sufficiently advanced to be able to generate authentically 'genuine' creative content?

### Ethical Considerations

This debate isn't just a legal one, there are also ethical considerations considerations data ownership. When Large Language Models generate content that closely resembles human-created works, it raises concerns about plagiarism, fair use, an essence of creativity. Does the model simply mimic existing styles, or does it possess a genuine spark of originality? Should the same standards of originality apply to AI-generated content as to human works?

Generative models have already had significant societal implications. If they can produce content indistinguishable from human-produced content, it could lead to job displacement in creative industries. The potential for misuse of these models, such as creating deepfakes for malicious purposes, also poses a serious threat to societal trust. Using ai-generated data to cyberbully has become a epidemic already. People's privacy and sense of security on the internet has been compromised. Malicious actors have already created large businesses out of renting their services to individuals generating undesirable content hurting others.

### The Legal Labyrinth

The legal landscape surrounding data ownership in LLM's is mostly uncharted territory. Existing copyright and intellectual property laws were designed for a world where humans were the sole creators. It's unclear if they are easily adaptable to the complexities of AI-generated content. This lack of clarity creates uncertainties for both creators and developers. It hinders innovation and stifles artistic expression.

### Beyond Ownership: A Collaborative Ecosystem

One way to move forward might be to shift the focus from singular ownership towards a joint-development and ownership ecosystem. This approach is one that could lead to shared prosperity: a system where data contributors, model developers, artists, and consumers work together to create a network where value is equitably shared. This might involve: 

* **Data Cooperatives:** Allowing data providers to collectively manage and monetize their data, ensuring they have a say in how it's used and receive fair compensation. This promotes data ownership and transparency within the ecosystem.

* **Open-Source Models:** Encouraging transparent development practices where algorithms are accessible for scrutiny and improvement. This promotes community innovation, mitigates potential biases, and allows for wider coordination on model development.

* **Creative Commons Licenses:** Implementing flexible licensing frameworks that allow for responsible use and adaptation of AI-generated content, while ensuring proper attribution and protecting rights. This strikes a balance between encouraging use and protecting intellectual property.

It is however easier said than done. Organizing millions, if not billions of individual contributors spread across decades is a hard task. Getting explicit consent for ai training on data already out there is impossible. A carefully-tread path might lead to some level of equity, but bad actors could ignore all safeguards and misuse the data for their personal gain, releasing the models to undermine efforts towards cooperative development.

### Upskilling and Reskilling for a Changing Landscape

The potential threat of job displacement in creative industries due to AI is real, we must prioritize proactive measures. Governments and educational institutions must collaborate to design upskilling and reskilling programs that equip professionals with the skills needed to adapt to the changing landscape, ensuring they thrive in the new ecosystem.

## Conclusion

In this essay I raised some concerns about the issue of data ownership in the era of generative AI models, and proposed a step towards a semblance of solution. It is important to acknowledge the legal and ethical complexities, and understand that the revolution is real, and undermining it would be a real step back in terms of productivity gains, if at all possible -- considering large models are open-source or have been leaked. We must ensure AI empowers creativity, fuels progress, and benefits all of humanity, specially those whose hard work over decades and centuries has helped us get here. 

Progress must not come at the cost of the livelihoods of millions of artists and creators who have followed the letter of the law in expectation of getting rewarded. The owners of powerful computational tools must not be the sole winners of our productive future: we must be guide ourselves by ethical principles and a shared vision for a brighter future. 

__Royalty-free stock image above from [Pexels](https://www.pexels.com/).__