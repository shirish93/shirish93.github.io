---
layout: post
title:  "LLM's will be the next spellcheck assistant, not the next robotic overlords!"
author: shirish
categories: [ ai, llm, collaboration]
featured: false
hidden: false
image: "assets/images/llm.jpg"
---

I've changed my opinion on genAI and LLM's a few times now. As technology, politics, and economics around these technologies change, my beliefs have evolved. In this essay I propose that generative AI will be mostly a collaborative revolution. Generative models can magnify human abilities and make collaboration easier. We have little to fear from them, despite what some Economic Consultants might want us to believe.

The printing press didn't eliminate scribes; it made their roles more important. AI won't render human creativity and jobs obsolete, it will change them. Imagine a creative struggling with writer's block. A generative model can give prompts, suggest phrasing, or help draft initial paragraphs. The writer's voice and idea are not replaced, the AI only speeds up the process. For customer service, AI chatbots can handle routine inquiries, freeing human agents for complex cases and personalized interactions.

Of course, generative models (GAI's) have their follies. They become specially important when deployed for use like customer interaction, for example. These large models are susceptible to the training data biases. They are capable of generating discriminatory or offensive response. Additionally, they are not deterministic, and their internal logic is not explainable. Which is to say, the 'bad situations' can be quite disastrous. And it would be mightily challenging to debug them after the fact.

Such "black box" nature of LLMs makes their decision-making opaque.  This lack of transparency is problematic. It's salient when an LLM generates harmful content or inaccurate predictions.  Advancements in Explainable AI (XAI) are needed to ensure transparency and build trust in these systems. As I write this, it's unclear how far we are, or if we'll even get there.

Focusing only on the risks leaves us with an incomplete picture though. There are some potential big wins with human-AI collaboration. Research teams have been working towards transparent, accountable, and responsible LLMs. It's unclear if future models will be 'unbiased' and in compliance of existing laws. Some researchers have suggested that to shape the output of LLM's in such a manner is fundamentally impossible.

Artists have used genAI to explore new creative possibilities. Medical startups are exploring using them for personalized patient care. Teachers have tested them to create tailored learning experiences. In the case of teaching though, the results have been overwhelmingly negative. But there's potential for opportunities where genAI can actually improve student learning, rather than decreasing engagement. The opportunity for GAI is wide and diverse. The hard part remains making sure they're 'human scale' and actually help us instead of undermining our goals.

We wil benefit by having a collaborative mindset towards AI usage. Staying out as a passive bystander, or as a fearful ai-phobe will put you at a disadvantage against your competitors. If they leverage these technologies to become efficient, reduce costs, and improve customer experience, you're left behind. And so, even if you're not completely sold on the technology, you must keep exploring.

__<a href="https://www.freepik.com/free-vector/robotic-process-automation-illustration_21743709.htm#fromView=search&page=1&position=28&uuid=14852b8d-0772-4624-97fc-6cf3a5b513be">Image by freepik</a>.__